{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhmAb/Drn4wOC4HwkKPZp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavlg/SFD/blob/main/NewFIlesGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faker pandas python-docx fpdf openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf_tWvLq0SDt",
        "outputId": "c976074e-db02-431c-d2c9-e3ef541919ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=198dc50d14642dbc8fe09cab06dc5b555afd32ec9f4ab845b2b8d0e5a2f327d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf, python-docx, faker\n",
            "Successfully installed faker-37.1.0 fpdf-1.7.2 python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r714GANw0LKt",
        "outputId": "3229849c-8259-4a81-e3d9-92003175093b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 documents have been saved in their respective directories!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from faker import Faker\n",
        "from fpdf import FPDF\n",
        "import pandas as pd\n",
        "from docx import Document\n",
        "\n",
        "# Initialize Faker and the document generators\n",
        "fake = Faker()\n",
        "Faker.seed(0)\n",
        "\n",
        "# Function to generate a single document's fake data\n",
        "def generate_document_data():\n",
        "    return {\n",
        "        \"UK_NINO\": fake.numerify(text=\"QQ#######A\"),\n",
        "        \"US_SSN\": fake.ssn(),\n",
        "        \"US_ITIN\": fake.numerify(text=\"9##-7#-####\"),\n",
        "        \"US_DRIVER_LICENSE\": fake.bothify(text=\"D##########\"),\n",
        "        \"US_BANK_NUMBER\": fake.bban(),\n",
        "        \"CREDIT_CARD\": fake.credit_card_number(card_type=None),\n",
        "        \"IBAN_CODE\": fake.iban(),\n",
        "        \"AADHAAR\": fake.numerify(text=\"#### #### ####\"),\n",
        "        \"IN_AADHAAR\": fake.numerify(text=\"#### #### ####\"),\n",
        "        \"IN_PAN\": fake.bothify(text=\"?????####?\").upper(),\n",
        "        \"IN_PASSPORT\": fake.bothify(text=\"??######\").upper(),\n",
        "        \"IN_VOTER\": fake.bothify(text=\"#### #### ####\"),\n",
        "        \"US_PASSPORT\": fake.bothify(text=\"C########\"),\n",
        "\n",
        "        \"MEDICAL_LICENSE\": fake.bothify(text=\"ML-#####\"),\n",
        "        \"CRYPTO\": fake.sha256(),\n",
        "        \"EMAIL_ADDRESS\": fake.email(),\n",
        "        \"PHONE_NUMBER\": fake.phone_number(),\n",
        "        \"IN_VEHICLE_REGISTRATION\": fake.bothify(text=\"DL##AB####\"),\n",
        "\n",
        "        \"PERSON\": fake.name(),\n",
        "        \"FIRST_NAME\": fake.first_name(),\n",
        "        \"LAST_NAME\": fake.last_name(),\n",
        "        \"LOCATION\": fake.city()\n",
        "    }\n",
        "\n",
        "\n",
        "# Function to save to a .txt file\n",
        "def save_to_txt(dir_name):\n",
        "  index=0\n",
        "  data = [generate_document_data() for _ in range(100)]\n",
        "  for doc in data:\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "    with open(f\"{dir_name}/documents_{index}.txt\", 'w') as f:\n",
        "          f.write(f\"Name: {doc['PERSON']}\\n\")\n",
        "          f.write(f\"Email: {doc['EMAIL_ADDRESS']}\\n\")\n",
        "          f.write(f\"Phone: {doc['PHONE_NUMBER']}\\n\")\n",
        "          f.write(f\"Aadhaar: {doc['AADHAAR']}\\n\")\n",
        "          f.write(f\"PAN: {doc['IN_PAN']}\\n\")\n",
        "          f.write(f\"Voter ID: {doc['IN_VOTER']}\\n\")\n",
        "          f.write(f\"Vehicle Reg: {doc['IN_VEHICLE_REGISTRATION']}\\n\")\n",
        "          f.write(f\"Credit Card: {doc['CREDIT_CARD']}\\n\")\n",
        "          f.write(f\"IBAN: {doc['IBAN_CODE']}\\n\\n\")\n",
        "          index+=1\n",
        "\n",
        "# Function to save to an Excel (.xlsx) file\n",
        "def save_to_excel(dir_name):\n",
        "   index=0\n",
        "   data = [generate_document_data() for _ in range(100)]\n",
        "   for doc in data:\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_excel(f\"{dir_name}/documents_{index}.xlsx\", index=False)\n",
        "    index+=1\n",
        "\n",
        "# Function to save to a CSV file\n",
        "def save_to_csv(dir_name):\n",
        "  index=0\n",
        "  data = [generate_document_data() for _ in range(100)]\n",
        "  for doc in data:\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(f\"{dir_name}/documents_{index}.csv\", index=False)\n",
        "    index+=1\n",
        "\n",
        "# Function to save to a .docx file\n",
        "def save_to_docx(dir_name):\n",
        "  index=0\n",
        "  data = [generate_document_data() for _ in range(100)]\n",
        "  for doc in data:\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "    doc = Document()\n",
        "    for doc_data in data:\n",
        "        doc.add_paragraph(f\"Name: {doc_data['PERSON']}\")\n",
        "        doc.add_paragraph(f\"Email: {doc_data['EMAIL_ADDRESS']}\")\n",
        "        doc.add_paragraph(f\"Phone: {doc_data['PHONE_NUMBER']}\")\n",
        "        doc.add_paragraph(f\"Aadhaar: {doc_data['AADHAAR']}\")\n",
        "        doc.add_paragraph(f\"PAN: {doc_data['IN_PAN']}\")\n",
        "        doc.add_paragraph(f\"Voter ID: {doc_data['IN_VOTER']}\")\n",
        "        doc.add_paragraph(f\"Vehicle Reg: {doc_data['IN_VEHICLE_REGISTRATION']}\")\n",
        "        doc.add_paragraph(f\"Credit Card: {doc_data['CREDIT_CARD']}\")\n",
        "        doc.add_paragraph(f\"IBAN: {doc_data['IBAN_CODE']}\")\n",
        "        doc.add_paragraph(\"\\n\")\n",
        "    doc.save(f\"{dir_name}/documents_{index}.docx\")\n",
        "    index+=1\n",
        "\n",
        "# Function to save to a PDF file\n",
        "def save_to_pdf(dir_name):\n",
        "  index=0\n",
        "  data = [generate_document_data() for _ in range(100)]\n",
        "  for doc in data:\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "    pdf = FPDF()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.add_page()\n",
        "\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    for doc_data in data:\n",
        "        pdf.cell(200, 10, f\"Name: {doc_data['PERSON']}\", ln=True)\n",
        "        pdf.cell(200, 10, f\"Email: {doc_data['EMAIL_ADDRESS']}\", ln=True)\n",
        "        pdf.cell(200, 10, f\"Phone: {doc_data['PHONE_NUMBER']}\", ln=True)\n",
        "        pdf.cell(200, 10, f\"Aadhaar: {doc_data['AADHAAR']}\", ln=True)\n",
        "        pdf.cell(200, 10, f\"PAN: {doc_data['IN_PAN']}\", ln=True)\n",
        "        pdf.cell(200, 10, f\"Voter ID: {doc_data['IN_VOTER']}\", ln=True)\n",
        "        pdf.cell(200, 10, f\"Vehicle Reg: {doc_data['IN_VEHICLE_REGISTRATION']}\", ln=True)\n",
        "        pdf.cell(200, 10, f\"Credit Card: {doc_data['CREDIT_CARD']}\", ln=True)\n",
        "        pdf.cell(200, 10, f\"IBAN: {doc_data['IBAN_CODE']}\", ln=True)\n",
        "        pdf.cell(200, 10, ln=True)\n",
        "\n",
        "    pdf.output(f\"{dir_name}/documents_{index}.pdf\")\n",
        "    index+=1\n",
        "\n",
        "# Loop to generate 100 sets of documents and save them in different directories\n",
        "save_to_txt(\"text_documents\")\n",
        "save_to_excel(\"excel_documents\")\n",
        "save_to_csv(\"csv_documents\")\n",
        "save_to_pdf(\"pdf_documents\")\n",
        "save_to_docx(\"word_documents\")\n",
        "\n",
        "print(\"100 documents have been saved in their respective directories!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XSj_nxLu31GB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}